{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/UnstructuredChatEval.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 4 eval questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the key metric for measuring success o...</td>\n",
       "      <td>Conversion to closed/won is pretty much the ke...</td>\n",
       "      <td>Conversion to won/closed is the key metric for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do you incentivize your sales and account ...</td>\n",
       "      <td>## Message: Hi - comp question for you all - h...</td>\n",
       "      <td>Growth AEs have 60/40 split between upsell boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the most crucial behaviors for someon...</td>\n",
       "      <td>## Message: Hey all! A nice high-level questio...</td>\n",
       "      <td>* Research things related to RevOps Roadmaps *...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are popular \"churn reason\" options on a d...</td>\n",
       "      <td>## Message: :wave: Hi All,  Creating a *churn ...</td>\n",
       "      <td>* Sales error * Onboarding challenge * Product...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the key metric for measuring success o...   \n",
       "1  How do you incentivize your sales and account ...   \n",
       "2  What are the most crucial behaviors for someon...   \n",
       "3  What are popular \"churn reason\" options on a d...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  Conversion to closed/won is pretty much the ke...   \n",
       "1  ## Message: Hi - comp question for you all - h...   \n",
       "2  ## Message: Hey all! A nice high-level questio...   \n",
       "3  ## Message: :wave: Hi All,  Creating a *churn ...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  Conversion to won/closed is the key metric for...  \n",
       "1  Growth AEs have 60/40 split between upsell boo...  \n",
       "2  * Research things related to RevOps Roadmaps *...  \n",
       "3  * Sales error * Onboarding challenge * Product...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (f\"You have {len(df)} eval questions\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Individual messages as documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_criteria = {\n",
    "    \"accuracy\": \"\"\"\n",
    "Score 1: The answer is completely unrelated to the reference.\n",
    "Score 3: The answer has minor relevance but does not align with the reference.\n",
    "Score 5: The answer has moderate relevance but contains inaccuracies.\n",
    "Score 7: The answer aligns with the reference but has minor errors or omissions.\n",
    "Score 10: The answer is completely accurate and aligns perfectly with the reference.\"\"\"\n",
    "}\n",
    "\n",
    "evaluator = load_evaluator(\"labeled_score_string\", criteria=accuracy_criteria, llm=ChatOpenAI(model='gpt-4-0125-preview'))\n",
    "\n",
    "# We can even override the model's learned knowledge using ground truth labels\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    input=df['question'].iloc[0],\n",
    "    prediction=\"Conversion to revenue paid as well as won/close\",\n",
    "    reference=df['ground_truth'].iloc[0],\n",
    ")\n",
    "print(f'With ground truth: {eval_result[\"score\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
